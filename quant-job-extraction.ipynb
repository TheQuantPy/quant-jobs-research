{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0d255e-f2a6-4476-9811-a03c48142558",
   "metadata": {},
   "source": [
    "## Quant Job Extraction\n",
    "\n",
    "Using serpAPI we will query quant jobs in the US and look for common skills and salary ranges for job titles and experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51b20e38-2f38-4024-956a-eb2c98a8a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa6e2a0b-1c81-41e8-aca0-17aaac69a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)  # Set logging level to INFO\n",
    "\n",
    "# Create a console handler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create a formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger (avoid duplicate handlers)\n",
    "if not logger.handlers:\n",
    "    logger.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17fdf015-035d-4d06-a765-7454637d9f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 6, 17, 8, 58, 24, 576129)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "645b8d73-9677-4353-9361-eb0bb5a0910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the key\n",
    "serpapi_key = os.getenv(\"SERPAPI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5b2cd17c-5e7f-4fef-b9ea-4d6eacff4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['Quantitative Researcher', 'Quantitative Analyst', 'Quantitative Trader', 'Algorithmic Trader', \n",
    "                'Quantitative Developer', 'Quantitative Software Engineer', 'Model Validation Quantitative Analyst', 'Model Validation Analyst',\n",
    "                'Quantitative Risk Analyst', 'Quantitative Portfolio Manager', 'Quantitative Investment Manager', 'Quantitative Asset Manager',\n",
    "                'Quantitative Strategist', 'Financial Engineer', 'Quantitative Pricing Analyst', 'Trader', \n",
    "                'Energy Trader', 'Energy Analyst', 'Power Trader'\n",
    "               ]\n",
    "search_locations_us = [\"New York, United States\", \"California, United States\", \n",
    "    \"Texas, United States\", \"Illinois, United States\", \"Florida, United States\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ae3db-327b-4ecb-ab63-f50b97c52c95",
   "metadata": {},
   "source": [
    "#### Serp API call\n",
    "\n",
    "Refined from lukebarousse repos https://github.com/lukebarousse/Data_Job_Pipeline_Airflow/blob/main/dags/serpapi_bigquery.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90b2be13-5db7-4e6a-b58a-92a423ef9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _serpapi_bigquery(search_term, search_location, search_time):\n",
    "    \"\"\"\n",
    "    Function to call SerpApi and insert results into BigQuery {gsearch_jobs_all} used by us_job_postings \n",
    "    and non_us_job_postings tasks\n",
    "\n",
    "    Args:\n",
    "        search_terms : list\n",
    "            List of search terms to search for\n",
    "        search_locations : list\n",
    "            List of search locations to search for\n",
    "        search_time : str\n",
    "            Time period to search for (e.g. 'past 24 hours')\n",
    "\n",
    "    Returns:\n",
    "        num_searches : int\n",
    "            Number of searches performed for this search term and location\n",
    "    \n",
    "    Source:\n",
    "        https://serpapi.com/google-jobs-results\n",
    "        https://cloud.google.com/bigquery/docs/reference/libraries\n",
    "    \"\"\"\n",
    "    next_page_token = None\n",
    "    num = 0\n",
    "    has_more_results = True\n",
    "    jobs_all = pd.DataFrame()  # Always initialize it\n",
    "\n",
    "    while has_more_results:\n",
    "        logger.debug(f\"START API CALL: {search_term} in {search_location} on search {num}\")\n",
    "\n",
    "        error = False\n",
    "        params = {\n",
    "            \"api_key\": serpapi_key,\n",
    "            \"device\": \"desktop\",\n",
    "            \"engine\": \"google_jobs\",\n",
    "            \"google_domain\": \"google.com\",\n",
    "            \"q\": search_term,\n",
    "            \"hl\": \"en\",\n",
    "            \"gl\": \"us\",\n",
    "            \"location\": search_location,\n",
    "            \"chips\": search_time,\n",
    "        }\n",
    "\n",
    "        if next_page_token:\n",
    "            params[\"next_page_token\"] = next_page_token\n",
    "\n",
    "        try:\n",
    "            search = GoogleSearch(params)\n",
    "            results = search.get_dict()\n",
    "\n",
    "            if 'error' in results:\n",
    "                logger.debug(f\"END SerpApi CALLS: {search_term} in {search_location} on search {num}: {results['error']}\")\n",
    "                error = True\n",
    "                break\n",
    "\n",
    "            logger.debug(f\"SUCCESS SerpApi CALL: {search_term} in {search_location} on search {num}\")\n",
    "\n",
    "            # Process results and insert into BigQuery\n",
    "            jobs = results['jobs_results']\n",
    "            jobs = pd.DataFrame(jobs)\n",
    "            jobs = pd.concat(\n",
    "                [jobs, pd.json_normalize(jobs['detected_extensions'])],\n",
    "                axis=1\n",
    "            ).drop('detected_extensions', axis=1)\n",
    "            jobs['date_time'] = datetime.now()\n",
    "\n",
    "            if num == 0:\n",
    "                jobs_all = jobs\n",
    "            else:\n",
    "                jobs_all = pd.concat([jobs_all, jobs])\n",
    "\n",
    "            jobs_all['search_term'] = search_term\n",
    "            jobs_all['search_location'] = search_location\n",
    "\n",
    "            # Check for next_page_token\n",
    "            if 'serpapi_pagination' in results and 'next_page_token' in results['serpapi_pagination']:\n",
    "                next_page_token = results['serpapi_pagination']['next_page_token']\n",
    "            else:\n",
    "                logger.debug(f\"END API CALLS: No more results for {search_term} in {search_location} on search {num}\")\n",
    "                has_more_results = False\n",
    "\n",
    "            num += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"SerpApi ERROR (Timeout)!!!: {search_term} in {search_location} had an error (most likely TimeOut)!!!\")\n",
    "            logger.error(f\"Following error returned: {e}\")\n",
    "            time.sleep(ERROR_SLEEP_MIN * 60)\n",
    "            error = True\n",
    "            break\n",
    "\n",
    "    # Insert data into BigQuery\n",
    "    if num > 0 and not error:\n",
    "\n",
    "        final_columns = ['title', 'company_name', 'location', 'via', 'description', 'extensions',\n",
    "                            'job_id', 'thumbnail', 'posted_at', 'schedule_type', 'salary',\n",
    "                            'work_from_home', 'date_time', 'search_term', 'search_location', 'commute_time']\n",
    "        jobs_all = jobs_all.loc[:, jobs_all.columns.isin(final_columns)]\n",
    "        \n",
    "\n",
    "\n",
    "    num_searches = num + 1\n",
    "\n",
    "    return jobs_all, num_searches   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a923d125-17c0-4d84-bb0c-5f9cfab9eff8",
   "metadata": {},
   "source": [
    "### Iterate over US jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5b2b390-caa2-4754-909d-0e0d67a8f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _us_jobs(search_terms, search_locations_us, **context):\n",
    "    \"\"\"\n",
    "    DAG to pull US job postings using the _serpapi_bigquery function\n",
    "\n",
    "    Args:\n",
    "        search_terms : list\n",
    "            List of search terms to search for\n",
    "        search_locations_us : list\n",
    "            List of search locations to search for\n",
    "        context : dict\n",
    "            Context dictionary from Airflow\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # search_time = \"date_posted:today\"\n",
    "    search_time = \"date_posted:month\"\n",
    "    total_searches = 0\n",
    "\n",
    "    all_jobs = []\n",
    "\n",
    "    for search_term in search_terms:\n",
    "        jobs_for_search_term = []\n",
    "    \n",
    "        for search_location in search_locations_us:\n",
    "            logger.debug(f\"START SEARCH: {total_searches} searches done, starting search...\")\n",
    "            jobs_all, num_searches = _serpapi_bigquery(search_term, search_location, search_time)   \n",
    "            total_searches += num_searches\n",
    "    \n",
    "            if jobs_all is not None and not jobs_all.empty:\n",
    "                jobs_for_search_term.append(jobs_all)\n",
    "    \n",
    "        if jobs_for_search_term:\n",
    "            # Concatenate all dataframes for this search term\n",
    "            jobs_for_search_term_df = pd.concat(jobs_for_search_term, ignore_index=True)\n",
    "            jobs_for_search_term_df.to_csv(f\"{search_term}.csv\", index=False)\n",
    "            all_jobs.append(jobs_for_search_term_df)\n",
    "\n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d08bbd96-f2d2-40d2-807e-2cda03c48af0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/tf/y1d6hw8d4455k554wzllp1180000gn/T/ipykernel_17747/4116933883.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_jobs = _us_jobs(search_terms, search_locations_us)\n\u001b[32m      2\u001b[39m all_jobs_df = pd.concat(all_jobs, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m all_jobs_df.to_csv(f\"all_jobs.csv\", index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m/var/folders/tf/y1d6hw8d4455k554wzllp1180000gn/T/ipykernel_17747/3244536522.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(search_terms, search_locations_us, **context)\u001b[39m\n\u001b[32m     23\u001b[39m         jobs_for_search_term = []\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m search_location \u001b[38;5;28;01min\u001b[39;00m search_locations_us:\n\u001b[32m     26\u001b[39m             logger.debug(f\"START SEARCH: {total_searches} searches done, starting search...\")\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m             jobs_all, num_searches = _serpapi_bigquery(search_term, search_location, search_time)\n\u001b[32m     28\u001b[39m             total_searches += num_searches\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m jobs_all \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m jobs_all.empty:\n",
      "\u001b[32m/var/folders/tf/y1d6hw8d4455k554wzllp1180000gn/T/ipykernel_17747/2825608424.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(search_term, search_location, search_time)\u001b[39m\n\u001b[32m     93\u001b[39m                             \u001b[33m'job_id'\u001b[39m, \u001b[33m'thumbnail'\u001b[39m, \u001b[33m'posted_at'\u001b[39m, \u001b[33m'schedule_type'\u001b[39m, \u001b[33m'salary'\u001b[39m,\n\u001b[32m     94\u001b[39m                             \u001b[33m'work_from_home'\u001b[39m, \u001b[33m'date_time'\u001b[39m, \u001b[33m'search_term'\u001b[39m, \u001b[33m'search_location'\u001b[39m, \u001b[33m'commute_time'\u001b[39m]\n\u001b[32m     95\u001b[39m         jobs_all = jobs_all.loc[:, jobs_all.columns.isin(final_columns)]\n\u001b[32m     96\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m jobs_all:\n\u001b[32m     98\u001b[39m         jobs_all = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     99\u001b[39m \n\u001b[32m    100\u001b[39m \n",
      "\u001b[32m~/Documents/dev/quant-jobs-research/env/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1575\u001b[39m     @final\n\u001b[32m   1576\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1577\u001b[39m         raise ValueError(\n\u001b[32m   1578\u001b[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001b[32m   1579\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1580\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "all_jobs = _us_jobs(search_terms, search_locations_us)\n",
    "all_jobs_df = pd.concat(all_jobs, ignore_index=True)\n",
    "all_jobs_df.to_csv(f\"all_jobs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a16fb-6683-49ad-8944-702018155173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of searches to perform daily\n",
    "MAX_SEARCHES = 1500\n",
    "\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fed5ce8-3cdd-48b3-92f3-3973f1e6bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classify countries by code and sort them by percentage of views\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def view_percent():\n",
    "    # import different country codes\n",
    "    codes = pd.read_csv(\"country_codes.csv\")\n",
    "\n",
    "    # import youtube views for my channel and calculate percentage viewed\n",
    "    views = pd.read_csv(\"youtube_views.csv\")\n",
    "    views = views.iloc[1: , :]\n",
    "    views = views[views.Views != 0] # removing countries with no views\n",
    "    views = views[views.Geography != 'US'] # pulling US already\n",
    "    views[\"percent\"] = views['Watch time (hours)'] / views['Watch time (hours)'].sum()\n",
    "\n",
    "    # no results returned from SerpApi from these countries\n",
    "    # may consider removing from search in future, but doesn' appear to use search credits for no results\n",
    "    no_country_results = [\"MO\", \"IR\", \"SD\", \"SY\", \"SZ\", \"SS\" ] # \"Macao\", \"Iran\", \"Sudan\", \"Syria\", \"Eswatini\", \"South Sudan\"\n",
    "\n",
    "    # merge dataframes for final dataframe\n",
    "    percent = views.merge(codes, how='left', left_on='Geography', right_on='code')\n",
    "    percent = percent[['country','percent']]\n",
    "    \n",
    "    # return the dataframe\n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc234eac-a5a4-4eee-8b9f-c16b205df975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>0.254927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.196187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>0.098563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada</td>\n",
       "      <td>0.063891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>0.061864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>0.050508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italy</td>\n",
       "      <td>0.028072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>0.026740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>0.024297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>0.019638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Poland</td>\n",
       "      <td>0.007893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>0.020422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>0.017436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>0.012342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>0.011555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0.012817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>0.007236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spain</td>\n",
       "      <td>0.009598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>0.012486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>0.010517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>0.004128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Norway</td>\n",
       "      <td>0.006007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>0.003735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>0.003958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>0.004430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Japan</td>\n",
       "      <td>0.004632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Chile</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>0.000789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Greece</td>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Israel</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Latvia</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>0.002959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Austria</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.001820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Romania</td>\n",
       "      <td>0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country   percent\n",
       "0            India  0.254927\n",
       "1   United Kingdom  0.196187\n",
       "2          Germany  0.098563\n",
       "3           Canada  0.063891\n",
       "4        Australia  0.061864\n",
       "5           France  0.050508\n",
       "6            Italy  0.028072\n",
       "7      Netherlands  0.026740\n",
       "8     South Africa  0.024297\n",
       "9           Brazil  0.019638\n",
       "10          Poland  0.007893\n",
       "11     Switzerland  0.020422\n",
       "12       Singapore  0.017436\n",
       "13       Hong Kong  0.012342\n",
       "14          Mexico  0.011555\n",
       "15       Indonesia  0.012817\n",
       "16         Vietnam  0.007236\n",
       "17           Spain  0.009598\n",
       "18          Turkey  0.012486\n",
       "19           Kenya  0.010517\n",
       "20        Thailand  0.004128\n",
       "21          Norway  0.006007\n",
       "22     South Korea  0.003735\n",
       "23          Sweden  0.004600\n",
       "24         Belgium  0.003958\n",
       "25         Denmark  0.004430\n",
       "26           Japan  0.004632\n",
       "27        Malaysia  0.001518\n",
       "28         Nigeria  0.001866\n",
       "29           Chile  0.000405\n",
       "30          Taiwan  0.000789\n",
       "31          Greece  0.000509\n",
       "32          Israel  0.001276\n",
       "33       Sri Lanka  0.002609\n",
       "34          Latvia  0.000986\n",
       "35       Lithuania  0.002959\n",
       "36        Colombia  0.000916\n",
       "37         Czechia  0.001686\n",
       "38         Ireland  0.000694\n",
       "39         Austria  0.001787\n",
       "40         Algeria  0.001820\n",
       "41           Egypt  0.000971\n",
       "42         Romania  0.000518\n",
       "43          Serbia  0.000214"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_percent = view_percent()\n",
    "\n",
    "country_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "de6dc712-efd9-42b4-938f-fcc91968b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of countries listed based on weighted probability to get random countries\n",
    "search_countries = list(country_percent.country)\n",
    "search_probabilities = list(country_percent.percent)\n",
    "search_locations = list(choice(search_countries, size=len(search_countries), replace=False, p=search_probabilities))\n",
    "non_searched = [search_location for search_location in search_locations if search_location not in ['United Kingdom', 'Australia', 'Canada', 'Singapore', 'Japan', 'Hong Kong', \n",
    "                            'Switzerland', 'Netherlands', 'Denmark', 'Germany', 'France', 'Spain', 'Italy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "47125359-9277-4762-8276-980228516d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _non_us_jobs(search_terms, country_percent, **context):\n",
    "    \"\"\"\n",
    "    DAG to pull non-US job postings using the _serpapi_bigquery function\n",
    "\n",
    "    Args:\n",
    "        search_terms : list\n",
    "            List of search terms to search for\n",
    "        country_percent : pandas dataframe\n",
    "            Dataframe of countries and their relative percent of total YouTube views for my channel\n",
    "        context : dict\n",
    "            Context dictionary from Airflow\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    Source:\n",
    "        https://youtube.com/@lukebarousse\n",
    "    \"\"\"\n",
    "    search_time = \"date_posted:month\"\n",
    "    search_countries = list(country_percent.country)\n",
    "    search_probabilities = list(country_percent.percent)\n",
    "    total_searches = 0\n",
    "\n",
    "    # create list of countries listed based on weighted probability to get random countries\n",
    "    search_locations = list(choice(search_countries, size=len(search_countries), replace=False, p=search_probabilities))\n",
    "    all_jobs = []\n",
    "        \n",
    "    for search_location in non_searched: #search_locations:\n",
    "        jobs_for_search_location = []\n",
    "        \n",
    "        if total_searches < MAX_SEARCHES:\n",
    "            logger.info(f\"SEARCHING COUNTRY: {search_location} [{search_locations.index(search_location)+1} of {len(search_locations)}]\")\n",
    "            for search_term in search_terms:\n",
    "                logger.debug(f\"SEARCHING TERM: {search_term}\")\n",
    "                logger.debug(f\"Starting search number {total_searches}...\")\n",
    "                jobs_all, num_searches = _serpapi_bigquery(search_term, search_location, search_time)   \n",
    "                total_searches += num_searches\n",
    "\n",
    "                if jobs_all is not None and not jobs_all.empty:\n",
    "                    jobs_for_search_location.append(jobs_all)                \n",
    "\n",
    "            if jobs_for_search_location:\n",
    "                # Concatenate all dataframes for this search term\n",
    "                jobs_for_search_location_df = pd.concat(jobs_for_search_location, ignore_index=True)\n",
    "                jobs_for_search_location_df.to_csv(f\"{search_location}.csv\", index=False)\n",
    "\n",
    "        else:\n",
    "            logger.info(f\"STICK A FORK IN ME, I'M DONE!!!!: {total_searches} searches complete\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c4322-2283-43bc-bca2-15e2c2e644b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 13:29:04,309 - INFO - SEARCHING COUNTRY: India [2 of 44]\n"
     ]
    }
   ],
   "source": [
    "_non_us_jobs(search_terms, country_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66906a5b-955b-4c35-8eb1-27e951975845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
